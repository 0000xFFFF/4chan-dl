#!/usr/bin/env python

import sys
import os
import subprocess
import argparse
import re
import requests
from bs4 import BeautifulSoup

# Argument parsing
parser = argparse.ArgumentParser(description='Download media (.jpg, .jpeg, .webm, ...) from 4chan.org with their posted filename')
parser.add_argument('-u', '--url', metavar='url', required=True, type=str, help="fetch vendor information for all MACs")
parser.add_argument('-d', '--directory', metavar='directory', default='.', type=str, help="directory to save files to")
args = parser.parse_args()

os.makedirs(args.directory, exist_ok=True)

headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36' }
response = requests.get(args.url, headers=headers)
soup = BeautifulSoup(response.content, 'html.parser')
file_divs = soup.find_all('div', class_='fileText')

n = len(file_divs)
for i, file_div in enumerate(file_divs):
    link = file_div.find('a')
    file_url = 'https:' + link['href']
    file_name = link['title'] if link.get('title') else file_url.split('/')[-1]
    file_path = os.path.join(args.directory, file_name)
    file_response = requests.get(file_url, headers=headers)
    with open(file_path, 'wb') as f:
        f.write(file_response.content)
    print(f"{i+1}/{n}: {file_name}")

print("All files downloaded.")
